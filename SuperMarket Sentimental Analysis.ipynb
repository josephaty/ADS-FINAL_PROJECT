{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk \n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 1.6 Millions rows dataset from csv file\n",
    "\n",
    "cols = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"tweet\"]\n",
    "encoding = 'latin'\n",
    "dataset = pd.read_csv('training.1600000.processed.noemoticon.csv',encoding=encoding,names=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment         ids                          date      flag  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1599995          4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996          4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997          4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998          4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999          4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                              tweet  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's substitute 0 to 0 and 4 to 1\n",
    "dataset['sentiment'].replace({0:0,4:1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset\n",
    "\n",
    "pattern = '@\\S+|https?:\\S+|http?:\\S|[^A-Za-z]+|com|net'\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(pattern, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            tokens.append(lemma.lemmatize(token))\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tweet = dataset.tweet.apply(lambda x: preprocess(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>upset update facebook texting might cry result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>dived many time ball managed save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>behaving mad see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>woke school best feeling ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>thewdb cool hear old walt interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>ready mojo makeover ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>happy th birthday boo alll time tupac amaru sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>1</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy charitytuesday thenspcc sparkscharity sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment         ids                          date      flag  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1599995          1  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996          1  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997          1  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998          1  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999          1  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                              tweet  \n",
       "0        _TheSpecialOne_       awww bummer shoulda got david carr third day  \n",
       "1          scotthamilton  upset update facebook texting might cry result...  \n",
       "2               mattycus    dived many time ball managed save rest go bound  \n",
       "3                ElleCTF                    whole body feel itchy like fire  \n",
       "4                 Karoli                                   behaving mad see  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028                      woke school best feeling ever  \n",
       "1599996      TheWDBoards                thewdb cool hear old walt interview  \n",
       "1599997           bpbabe                     ready mojo makeover ask detail  \n",
       "1599998     tinydiamondz  happy th birthday boo alll time tupac amaru sh...  \n",
       "1599999   RyanTrevMorris  happy charitytuesday thenspcc sparkscharity sp...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into Training and Test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "dataset_train,dataset_test = train_test_split(dataset,test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_clean = dataset_train[['sentiment','tweet']]\n",
    "dataset_test_clean = dataset_test[['sentiment','tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564746</th>\n",
       "      <td>0</td>\n",
       "      <td>already crappy day n barely started yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453999</th>\n",
       "      <td>1</td>\n",
       "      <td>going sunday market birkelunden first time ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814882</th>\n",
       "      <td>1</td>\n",
       "      <td>goodmorning every rejoice today new day ur tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005780</th>\n",
       "      <td>1</td>\n",
       "      <td>haha talking soup noodle lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235693</th>\n",
       "      <td>0</td>\n",
       "      <td>want get good grade something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742853</th>\n",
       "      <td>0</td>\n",
       "      <td>fell asleep really late woke really early good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391730</th>\n",
       "      <td>1</td>\n",
       "      <td>dont know buy yet like sims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310813</th>\n",
       "      <td>0</td>\n",
       "      <td>make heat look like could change friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233550</th>\n",
       "      <td>0</td>\n",
       "      <td>arthur smith last night silent disco awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110776</th>\n",
       "      <td>0</td>\n",
       "      <td>raining</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet\n",
       "564746           0            already crappy day n barely started yet\n",
       "1453999          1    going sunday market birkelunden first time ever\n",
       "814882           1  goodmorning every rejoice today new day ur tro...\n",
       "1005780          1                     haha talking soup noodle lunch\n",
       "235693           0                      want get good grade something\n",
       "...            ...                                                ...\n",
       "742853           0     fell asleep really late woke really early good\n",
       "1391730          1                        dont know buy yet like sims\n",
       "310813           0            make heat look like could change friday\n",
       "233550           0       arthur smith last night silent disco awesome\n",
       "110776           0                                            raining\n",
       "\n",
       "[1440000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_clean.head(1600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 20\n",
    "trunc_type = 'post'\n",
    "padd_type = 'post'\n",
    "\n",
    "\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(dataset_train_clean['tweet'])\n",
    "\n",
    "training_seq = tokens.texts_to_sequences(dataset_train_clean['tweet'])\n",
    "X_train = pad_sequences(training_seq,maxlen = max_length,padding=padd_type,truncating=trunc_type)\n",
    "\n",
    "testing_seq =  tokens.texts_to_sequences(dataset_test_clean['tweet'])\n",
    "X_test = pad_sequences(testing_seq,maxlen = max_length,padding=padd_type,truncating=trunc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring target labels \n",
    "y_train = dataset_train_clean['sentiment']\n",
    "y_test = dataset_test_clean['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting everything to numpy arrays\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "\n",
    "word2vec_dict = word2vec.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary = True)\n",
    "\n",
    "\n",
    "embeddings_index = dict()\n",
    "for word in word2vec_dict.vocab:\n",
    "    embeddings_index[word] = word2vec_dict.word_vec(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokens.word_index) + 1\n",
    "\n",
    "embed_size = 300\n",
    "embedding_matrix = np.zeros((vocab_size,embed_size))\n",
    "\n",
    "for word,tok in tokens.word_index.items():\n",
    "    if word in embeddings_index.keys():\n",
    "        embedding_vector = embeddings_index[word]\n",
    "        embedding_matrix[tok] =  embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding,Dense,LSTM,Bidirectional\n",
    "from tensorflow.keras.layers import BatchNormalization,Dropout\n",
    "\n",
    "embedding_layer = Embedding(vocab_size,embed_size,weights = [embedding_matrix],input_length = max_length,trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(64,return_sequences = True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(32,activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "176/176 [==============================] - 1041s 6s/step - loss: 0.5274 - accuracy: 0.7358\n",
      "Epoch 2/5\n",
      "176/176 [==============================] - 1023s 6s/step - loss: 0.4791 - accuracy: 0.7717\n",
      "Epoch 3/5\n",
      "176/176 [==============================] - 1159s 7s/step - loss: 0.4648 - accuracy: 0.7805\n",
      "Epoch 4/5\n",
      "176/176 [==============================] - 1027s 6s/step - loss: 0.4557 - accuracy: 0.7864\n",
      "Epoch 5/5\n",
      "176/176 [==============================] - 1101s 6s/step - loss: 0.4487 - accuracy: 0.7907\n"
     ]
    }
   ],
   "source": [
    "# Training a model \n",
    " \n",
    "batch_size = 8192\n",
    "num_epochs = 5\n",
    "\n",
    "brain = model.fit(X_train,y_train,batch_size = batch_size,epochs = num_epochs,verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 50s 3s/step - loss: 0.4530 - accuracy: 0.7858\n",
      "\n",
      "Accuracy of model is : 78.58%\n",
      "Loss of model is :45.3%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(\"\")\n",
    "print(f\"Accuracy of model is : {round(score[1]*100,2)}%\")\n",
    "print(f\"Loss of model is :{round(score[0]*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a model to make prediction\n",
    "\n",
    "def decode_sentiment(score):\n",
    "    label = None\n",
    "    if score <= 0.45:\n",
    "        label = 'Negative'\n",
    "    elif score >= 0.55:\n",
    "        label = 'Positive'\n",
    "    else:\n",
    "        label = 'Neutral'\n",
    "    \n",
    "    return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    x_test = pad_sequences(tokens.texts_to_sequences([text]), maxlen=max_length,padding=padd_type,truncating=trunc_type)\n",
    "    score = model.predict([x_test])[0]\n",
    "    \n",
    "    label = decode_sentiment(score)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your name ?: MAYAGI NESTORY JOSEPHATY\n",
      " Hello, MAYAGI NESTORY JOSEPHATY!, To Get Started Type 'Help or H'\n",
      ": Help\n",
      "\n",
      "            ----------------------------\n",
      "                   Menu\n",
      "            ----------------------------\n",
      "            Tweet or T - To write Tweet\n",
      "            Help  or H - To Display Menu\n",
      "            Quit  or Q - To Exit Program\n",
      "            ----------------------------\n",
      "        \n",
      ": Tweet\n",
      "What is your tweet ? This item is too expensive, I can't afford to buy it.\n",
      " This tweet is NEGATIVE and Score of 11.25%\n",
      "\n",
      "Do you Want to Enter Another Tweet? (Y/N): Y\n",
      "\n",
      "What is your tweet ? I like iphone 13 pro max, one day i will buy it.\n",
      " This tweet is POSITIVE and Score of 57.04%\n",
      "\n",
      "Do you Want to Enter Another Tweet? (Y/N): Y\n",
      "\n",
      "What is your tweet ? I always buy milkshake from this restaurant, it is too delicious.\n",
      " This tweet is POSITIVE and Score of 91.98%\n",
      "\n",
      "Do you Want to Enter Another Tweet? (Y/N): N\n",
      "\n",
      "Goodbye, MAYAGI NESTORY JOSEPHATY!\n"
     ]
    }
   ],
   "source": [
    "name = input('What is your name ?: ').upper()\n",
    "\n",
    "print(f\" Hello, {name}!, To Get Started Type 'Help or H'\")\n",
    "\n",
    "command = \"\"\n",
    "\n",
    "while command != \"quit\" or command != \"q\":\n",
    "    \n",
    "    def goodbye():\n",
    "        print(f\"Goodbye, {name}!\")\n",
    "        \n",
    "        \n",
    "    def sentiment():\n",
    "        message = input(\"What is your tweet ? \")\n",
    "        dict = predict(message)\n",
    "        score = round(float(dict['score']) * 100,2)\n",
    "        sentiment = dict['label'].upper()\n",
    "        print(f\" This tweet is {sentiment} and Score of {score}%\")\n",
    "        print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    command = input(\": \").lower()\n",
    "\n",
    "    if command == \"help\" or command == \"h\":\n",
    "        print(\"\"\"\n",
    "            ----------------------------\n",
    "                   Menu\n",
    "            ----------------------------\n",
    "            Tweet or T - To write Tweet\n",
    "            Help  or H - To Display Menu\n",
    "            Quit  or Q - To Exit Program\n",
    "            ----------------------------\n",
    "        \"\"\")\n",
    "\n",
    "    elif command == \"tweet\" or command == \"t\":\n",
    "        sentiment()\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            command01 = input(\"Do you Want to Enter Another Tweet? (Y/N): \").lower()\n",
    "            print(\"\")\n",
    "            \n",
    "            if command01 == \"y\":\n",
    "                sentiment()\n",
    "                \n",
    "            elif command01 == \"n\":\n",
    "                goodbye()\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    elif command == \"quit\" or command == \"q\":\n",
    "        goodbye()\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        print(\"Please, type 'Help' for proper input.!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
